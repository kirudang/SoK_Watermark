
# SoK: Are Watermarks in LLMs Ready for Deployment?

## Requirements
To set up the environment for this project, it's recommended to create a dedicated environment and install the required packages listed in `requirements.txt`.

```bash
conda create -n env python=3.10
conda activate env
pip install -r requirements.txt
```

## Experiments with the Cross-Model IP Classifier
All code used in our paper is located in the `src/` folder, with datasets available in the `data/` folder. Detailed instructions on reproducing the results or training the model with your dataset are provided below.

### Step 1: Watermark Implementation
To use the classifier, we first need input text generated by LLMs, along with the watermarked versions to create training and testing datasets. It's advisable to label text generated from different LLMs or watermarks with a numeric identifier, e.g., 1, 2, 3.

We store generated text and watermarked text in json file with sample format like this to facilitate implementing the IP Classifier without minor modification.

```json
{
    "input": "... 8i’s platform will let you create, experience, and",
    "input_output": " ... 8i’s platform will let you create, experience, and share 3D content like never before, and the company has a few demos ...",
    "output_only": "share 3D content like never before, and the company has a few demos ...",
    "label": 1,
    "train": 1
}
```
To generate no watermark text from base LLM, please use sample code at: `src/No_Watermark_Sample_Implementation`

For generating text with watermarks, follow the original settings specified in the following resources for each type of watermark:
- **KGW**: [KGW Watermark Repository](https://github.com/jwkirchenbauer/lm-watermarking)
- **EXP**: [EXP Watermark Repository](https://github.com/jthickstun/watermark)
- **SIR**: [SIR Watermark Repository](https://github.com/THU-BPM/Robust_Watermark)
- **SemStamp**: [SemStamp Watermark Repository](https://github.com/bohanhou14/SemStamp)
- **Unigram**: [Unigram Watermark Repository](https://github.com/XuandongZhao/Unigram-Watermark)
- **Adaptive**: [Adaptive Watermark Repository](https://github.com/yepengliu/adaptive-text-watermarks)
- **UPV**: [Unforgeable Watermark Repository](https://github.com/THU-BPM/unforgeable_watermark)

We also provide a sample code to generate watermarked text of KGW with our C4 data at: `src/KGW_Sample_Implementation` . The rest of watermark schemes follow the similar integration. 


### Step 2: Classify Text using the IP Classifier
We provide four main types of classifiers in `src/IP_Classifier`:
1. Non-transformer using LSTM
2. Decoder-based transformer
3. Encoder-based transformer
4. Encoder-Decoder transformer

For each classifier type, you only need to update the model name and data. All parameters are clearly stated in the code.
For example, if you use Decoder-based transformer IP Checker (gpt2) to classify 3 output types from Llama (label 1), Mistral (label 2), OPT (label 3), you can use:
```bash
type_of_label = [1, 2, 3]  # or any other labels you want to filter
base_model = "gpt2"
```
Note: Make sure, each type has both training (1) and testing (0) data in your set since this is supervised classification task.

### Data
- **Training data**: Available at `data/c4_promt_test.pt`
- **Testing data**: Available at `data/c4_promt_train.pt`

Feel free to explore and enjoy the code!
